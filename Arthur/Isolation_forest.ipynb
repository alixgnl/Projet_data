{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import scipy.io as sp\n",
    "from sklearn.ensemble import IsolationForest, BaggingClassifier\n",
    "\n",
    "dataSet = sp.loadmat('breastw.mat')\n",
    "X = dataSet['X']\n",
    "y = dataSet['y']\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88       222\n",
      "           1       0.94      0.53      0.68       120\n",
      "\n",
      "    accuracy                           0.82       342\n",
      "   macro avg       0.87      0.76      0.78       342\n",
      "weighted avg       0.85      0.82      0.81       342\n",
      "\n",
      "[[218   4]\n",
      " [ 56  64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85       222\n",
      "           1       0.92      0.40      0.56       120\n",
      "\n",
      "    accuracy                           0.78       342\n",
      "   macro avg       0.84      0.69      0.70       342\n",
      "weighted avg       0.81      0.78      0.75       342\n",
      "\n",
      "[[218   4]\n",
      " [ 72  48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       222\n",
      "           1       0.97      0.66      0.78       119\n",
      "\n",
      "    accuracy                           0.87       341\n",
      "   macro avg       0.91      0.82      0.85       341\n",
      "weighted avg       0.89      0.87      0.87       341\n",
      "\n",
      "[[220   2]\n",
      " [ 41  78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       222\n",
      "           1       0.98      0.42      0.59       119\n",
      "\n",
      "    accuracy                           0.79       341\n",
      "   macro avg       0.87      0.71      0.73       341\n",
      "weighted avg       0.84      0.79      0.77       341\n",
      "\n",
      "[[221   1]\n",
      " [ 69  50]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, confusion_matrix, roc_curve, precision_recall_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(X, y) #get and split return n split\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = IsolationForest(contamination=0.15, n_estimators=10)\n",
    "    model.fit(X_train)\n",
    "    #print(model.predict(X_test))\n",
    "    #model1 = [0 if elem == 1 else elem for elem in model.predict(X_test)]\n",
    "    #print(\"nouvelle liste : \" + str(model1))\n",
    "    #model2 = [1 if elem == -1 else elem for elem in model1]\n",
    "    #print(\"nouvelle liste : \" + str(model2))\n",
    "    y_pred=model.predict(X_test)\n",
    "    y_pred[y_pred>0]=0\n",
    "    y_pred[y_pred<0]=1\n",
    "    y_pred1=model.fit_predict(X_test)\n",
    "    y_pred1[y_pred1>0]=0\n",
    "    y_pred1[y_pred1<0]=1\n",
    "    #y_pred =  model2\n",
    "    #plt.figure(figsize=(10,7))\n",
    "    #plt.subplot(121)\n",
    "    #plt.title(\"Prédiction avec KMeans\")\n",
    "    #plt.scatter(X[:,0],X[: , 1], c=y_pred)\n",
    "    #plt.scatter(model.cluster_centers_[:,0],model.cluster_centers_[:,1], c='r')\n",
    "    #plt.subplot(122)\n",
    "    #plt.title(\"Répartition initiale\")\n",
    "    #plt.scatter(X[:,0], X[:,1], c=y)\n",
    "    #model.inertia_ \n",
    "    #if precision_score(y_test,y_pred)< 0.15:\n",
    "    #y_pred = np.array([0 if label == 1 else 1 for label in y_pred])\n",
    "    #print (y_pred)\n",
    "    #print (y_test)\n",
    "    \n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test,y_pred1))\n",
    "    print(confusion_matrix(y_test, y_pred1))\n",
    "    \n",
    "    \n",
    "    #isolation_fpr, isolation_tpr, threshold = roc_curve(y_test, y_pred)\n",
    "    #auc_isolation = auc(isolation_fpr, isolation_tpr)\n",
    "    #plt.figure(figsize=(5, 5), dpi=100)\n",
    "    #plt.plot(isolation_fpr, isolation_tpr, marker='.', label='Isolation (auc = %0.3f)' % auc_isolation)\n",
    "    #plt.xlabel('False Positive Rate -->')\n",
    "    \"\"\"plt.ylabel('True Positive Rate -->')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "       \"\"\"\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "894588d70223105318f3a6143f469ff55b12e3d45628534b2f37efc006a33ec3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
