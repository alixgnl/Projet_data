{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sp\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, f1_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from scipy.stats import kruskal\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "dataSet = sp.loadmat('breastw.mat')\n",
    "X = dataSet['X']\n",
    "y = dataSet['y']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10) \n",
    "\n",
    "test = False\n",
    "test2 = False\n",
    "test3 = False\n",
    "test4 = False\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "   \n",
    "\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # utilisation de la méthode gaussienne \n",
    "    gmm = GaussianMixture(n_components=2,init_params='kmeans',covariance_type='diag') # appel  de la fonction gaussian mixture\n",
    "    gmm.fit(X_train,y_train) # entrainement du modèle \n",
    "    y_pred_gmm=gmm.predict(X_test)# prédiction du modèle sur les X_test\n",
    "    if precision_score(y_test,y_pred_gmm)< 0.05: # interversion des labels en cas de problème de labelisation\n",
    "\n",
    "        y_pred_gmm = np.array([0 if label == 1 else 1 for label in y_pred_gmm])\n",
    "    \n",
    "    F1=round(f1_score(y_test,y_pred_gmm),3) # récupération de la valeur F1_score\n",
    "\n",
    "\n",
    "    if test==False :\n",
    "            data = np.array([[F1]]) # on rentre les valeurs de F1 dans un array\n",
    "            test=True\n",
    "    else :\n",
    "            data = np.append(data,np.array([F1]).reshape(1,1),axis=0) # si l'array est déja crée, on ajoute les scores dans le array déja crée\n",
    "    ########\n",
    "    # utilisation de la méthode KNN\n",
    "    model_KNN = KNeighborsClassifier(n_neighbors=16, weights='distance', algorithm='auto', metric='braycurtis')# appel de la méthode KNN\n",
    "    model_KNN.fit(X_train,y_train)# entrainement du modèle\n",
    "    y_pred_KNN = model_KNN.predict(X_test)# prédiction du modèle sur X_test\n",
    "    F1_knn=round(f1_score(y_test,y_pred_KNN),3)# récupération du score F1 pour KNN\n",
    "    \n",
    "    # même logique ici que pour gaussian mixture\n",
    "    if test2==False :\n",
    "            KNN = np.array([[F1_knn]])\n",
    "            test2=True\n",
    "    else :\n",
    "            KNN = np.append(KNN,np.array([F1_knn]).reshape(1,1),axis=0)\n",
    "    ###########\n",
    "    # utilisation du modèle réseaux de neurones \n",
    "    model_PMC_1 = MLPClassifier(solver='lbfgs',alpha=0.1, hidden_layer_sizes=(4, 4),random_state=1 )# appel de la méthode réseaux de neurones\n",
    "    model_PMC_1.fit(X_train, y_train)# entrainement du modèle\n",
    "    y_pred_PMC_1= model_PMC_1.predict(X_test)# prédiction du modèle sur X_test\n",
    "    if precision_score(y_test,y_pred_PMC_1)< 0.05: # interversion des labels en cas de problème de labelisation\n",
    "\n",
    "        y_pred_PMC_1 = np.array([0 if label == 1 else 1 for label in y_pred_PMC_1])\n",
    "    F1_Neurones=round(f1_score(y_test, y_pred_PMC_1),3)# récupération du score F1\n",
    "    if test3==False :\n",
    "            Neurones = np.array([[F1_Neurones]])\n",
    "            test3=True\n",
    "    else :\n",
    "            Neurones = np.append(Neurones,np.array([F1_Neurones]).reshape(1,1),axis=0)\n",
    "   #############\n",
    "   # utilisation du modèle  perceptron \n",
    "    PerceP = Perceptron(penalty ='l1',alpha =1,l1_ratio=1e-6, max_iter=50) # appel de la méthode perceptron \n",
    "    PerceP.fit(X_train, y_train)# entrainement du modèle\n",
    "    y_pred_PSC = PerceP.predict(X_test)# prédiction du modèle \n",
    "    F1_Perceptron=round(f1_score(y_test, y_pred_PSC),3) # récupération du score F1\n",
    "    if test4==False :\n",
    "            perceptron = np.array([[F1_Perceptron]])\n",
    "            test4=True\n",
    "    else :\n",
    "            perceptron = np.append(perceptron,np.array([F1_Perceptron]).reshape(1,1),axis=0)\n",
    "   ##########\n",
    "# conversion des np.array en dataframe  \n",
    "df = pd.DataFrame(data,columns=['[{}]'.format(\"Gaussian\")])\n",
    "df1 = pd.DataFrame(KNN,columns=['[{}]'.format(\"KNN\")])\n",
    "df2 = pd.DataFrame(Neurones,columns=['[{}]'.format(\"Réseaux neurones\")])\n",
    "df3 = pd.DataFrame(perceptron,columns=['[{}]'.format(\"Perceptron\")])\n",
    "\n",
    "Comparaison = pd.concat([df, df1,df2,df3], axis = 1) # on concatène toutes les colonnes\n",
    "\n",
    "display(Comparaison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp\n",
    "\n",
    "# comparaison des variances avec le t-statistiques et la p-value\n",
    "t,p = kruskal(Comparaison['[Gaussian]'],Comparaison['[KNN]'],Comparaison['[Réseaux neurones]'],Comparaison['[Perceptron]'])\n",
    "print('t statistic: %.3f' % t)\n",
    "print('p value: %.20f' % p)\n",
    "# comparaison des variances entre algorithme 1 à 1\n",
    "sp.posthoc_conover([Comparaison['[Gaussian]'],Comparaison['[KNN]'],Comparaison['[Réseaux neurones]'],Comparaison['[Perceptron]']])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
