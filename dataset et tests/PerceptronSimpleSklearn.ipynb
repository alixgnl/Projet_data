{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPP = Perceptron(penalty=\\'elasticnet\\') #random_state=42\\nPP.fit(X_train, y_train)\\npredictions_test = PP.predict(X_test)\\n\\n#Accuracy\\nresult1 = accuracy_score(y_test,predictions_test)\\nprint(\"Accuracy 1 :\",result1)\\n\\n#ROC curve\\nclf_isotonic = CalibratedClassifierCV(PP, cv=\\'prefit\\', method=\\'isotonic\\') #il faut encore fait la validation croisée au début (équilibrer notre dataset)\\n#CV correspond à la validation croisée, si dataset déjà rééquilibré : cv = \\'predict\\'\\nclf_isotonic.fit(X_test, y_test)\\npreds = clf_isotonic.predict_proba(X_test)\\n\\n#y_scores1 = PP.predict_proba(X_test) #il ne connaît pas predict_proba\\nfpr, tpr, threshold = roc_curve(y_test, preds[:, 1])\\nroc_auc = auc(fpr, tpr)\\nprint(\"AUC 1 : \", roc_auc)\\n\\nplt.title(\\'Receiver Operating Characteristic\\')\\nplt.plot(fpr, tpr, \\'b\\', label = \\'AUC 1 = %0.2f\\' % roc_auc)\\nplt.legend(loc = \\'lower right\\')\\nplt.plot([0, 1], [0, 1],\\'r--\\')\\nplt.xlim([0, 1])\\nplt.ylim([0, 1])\\nplt.ylabel(\\'True Positive Rate\\')\\nplt.xlabel(\\'False Positive Rate\\')\\nplt.title(\\'ROC Curve Simple Perceptron\\')\\nplt.show()\\n\\n\\ndef create(row, col):\\n    return [[[]for _ in range(col)]  for _ in range(row)]\\n\\npenalty = [\\'l1\\', \\'l2\\',\\'elasticnet\\',\\'None\\']\\nMax_iter = []\\nfor k in range (1,15):\\n    Max_iter.append(50*k)\\nEta =[]\\nfor k in range (-5,3):\\n    Eta.append(10**(-k)) \\nAlpha = []\\nfor k in range (0,5):\\n    Alpha.append(10**(-k))\\n\\nMC = create(len(penalty)*len(Max_iter)*,3)\\nMC[0][0]=\\'penalty\\'\\nMC[0][1]=\\'AUC\\'\\nMC[0][2]=\\'Accuracy\\'\\ni=1\\n\\nfor k in penalty:\\n    \\n    MC[i][0]= k\\n\\n    PP = Perceptron(penalty=k) #random_state=42\\n    PP.fit(X_train, y_train)\\n    predictions_test = PP.predict(X_test)\\n\\n        \\n    #ROC curve\\n    clf_isotonic = CalibratedClassifierCV(PP, cv=\\'prefit\\', method=\\'isotonic\\') #il faut encore fait la validation croisée au début (équilibrer notre dataset)\\n    #CV correspond à la validation croisée, si dataset déjà rééquilibré : cv = \\'predict\\'\\n    clf_isotonic.fit(X_test, y_test)\\n    preds = clf_isotonic.predict_proba(X_test)\\n\\n    #y_scores1 = PP.predict_proba(X_test) #il ne connaît pas predict_proba\\n    fpr, tpr, threshold = roc_curve(y_test, preds[:, 1])\\n    roc_auc = auc(fpr, tpr)\\n    \\n    #Accuracy\\n    result1 = accuracy_score(y_test,predictions_test)\\n    \\n    MC[i][1]=(round(roc_auc, 6))\\n    MC[i][2]= result1\\n            \\n    i += 1 \\n\\nprint(MC)\\nworkbook = xlsxwriter.Workbook(\\'Comparaison matrice Perceptron simple.xlsx\\')\\nworksheet = workbook.add_worksheet()\\ncol = 0\\nfor row, data in enumerate(MC):\\n    worksheet.write_row(row, col, data)\\nworkbook.close()\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_score, classification_report, confusion_matrix, accuracy_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import scipy.io as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import xlsxwriter\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Traitement du fichier .mat\n",
    "cancercell = sp.loadmat('breastw.mat')\n",
    "X = cancercell['X']\n",
    "y = cancercell['y']\n",
    "#print(cancercell)\n",
    "y=np.reshape(y,(683,))\n",
    "#Séparation des données d'apprentissage et des données tests\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y)\n",
    "#fin traitement mat\n",
    "\n",
    "\"\"\"\n",
    "PP = Perceptron(penalty='elasticnet') #random_state=42\n",
    "PP.fit(X_train, y_train)\n",
    "predictions_test = PP.predict(X_test)\n",
    "\n",
    "#Accuracy\n",
    "result1 = accuracy_score(y_test,predictions_test)\n",
    "print(\"Accuracy 1 :\",result1)\n",
    "\n",
    "#ROC curve\n",
    "clf_isotonic = CalibratedClassifierCV(PP, cv='prefit', method='isotonic') #il faut encore fait la validation croisée au début (équilibrer notre dataset)\n",
    "#CV correspond à la validation croisée, si dataset déjà rééquilibré : cv = 'predict'\n",
    "clf_isotonic.fit(X_test, y_test)\n",
    "preds = clf_isotonic.predict_proba(X_test)\n",
    "\n",
    "#y_scores1 = PP.predict_proba(X_test) #il ne connaît pas predict_proba\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"AUC 1 : \", roc_auc)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC 1 = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve Simple Perceptron')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def create(row, col):\n",
    "    return [[[]for _ in range(col)]  for _ in range(row)]\n",
    "\n",
    "penalty = ['l1', 'l2','elasticnet','None']\n",
    "Max_iter = []\n",
    "for k in range (1,15):\n",
    "    Max_iter.append(50*k)\n",
    "Eta =[]\n",
    "for k in range (-5,3):\n",
    "    Eta.append(10**(-k)) \n",
    "Alpha = []\n",
    "for k in range (0,5):\n",
    "    Alpha.append(10**(-k))\n",
    "\n",
    "MC = create(len(penalty)*len(Max_iter)*,3)\n",
    "MC[0][0]='penalty'\n",
    "MC[0][1]='AUC'\n",
    "MC[0][2]='Accuracy'\n",
    "i=1\n",
    "\n",
    "for k in penalty:\n",
    "    \n",
    "    MC[i][0]= k\n",
    "\n",
    "    PP = Perceptron(penalty=k) #random_state=42\n",
    "    PP.fit(X_train, y_train)\n",
    "    predictions_test = PP.predict(X_test)\n",
    "\n",
    "        \n",
    "    #ROC curve\n",
    "    clf_isotonic = CalibratedClassifierCV(PP, cv='prefit', method='isotonic') #il faut encore fait la validation croisée au début (équilibrer notre dataset)\n",
    "    #CV correspond à la validation croisée, si dataset déjà rééquilibré : cv = 'predict'\n",
    "    clf_isotonic.fit(X_test, y_test)\n",
    "    preds = clf_isotonic.predict_proba(X_test)\n",
    "\n",
    "    #y_scores1 = PP.predict_proba(X_test) #il ne connaît pas predict_proba\n",
    "    fpr, tpr, threshold = roc_curve(y_test, preds[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    #Accuracy\n",
    "    result1 = accuracy_score(y_test,predictions_test)\n",
    "    \n",
    "    MC[i][1]=(round(roc_auc, 6))\n",
    "    MC[i][2]= result1\n",
    "            \n",
    "    i += 1 \n",
    "\n",
    "print(MC)\n",
    "workbook = xlsxwriter.Workbook('Comparaison matrice Perceptron simple.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "col = 0\n",
    "for row, data in enumerate(MC):\n",
    "    worksheet.write_row(row, col, data)\n",
    "workbook.close()\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penalty</th>\n",
       "      <th>Max_iter</th>\n",
       "      <th>Eta</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>elasticnet</td>\n",
       "      <td>700</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>elasticnet</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>elasticnet</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>elasticnet</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>elasticnet</td>\n",
       "      <td>150</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>l1</td>\n",
       "      <td>600</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.985</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>l1</td>\n",
       "      <td>600</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.985</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>l1</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>l1</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.985</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>l2</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.985</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         penalty Max_iter    Eta   Alpha  F1 score  Recall  Precision  \\\n",
       "1676  elasticnet      700   0.01     0.1      1.00     1.0       1.00   \n",
       "1516  elasticnet      500   0.01     0.1      1.00     1.0       1.00   \n",
       "1156  elasticnet       50   0.01     0.1      1.00     1.0       1.00   \n",
       "1196  elasticnet      100   0.01     0.1      1.00     1.0       1.00   \n",
       "1236  elasticnet      150   0.01     0.1      1.00     1.0       1.00   \n",
       "...          ...      ...    ...     ...       ...     ...        ...   \n",
       "449           l1      600  10000  0.0001      0.98     1.0       0.96   \n",
       "464           l1      600     10  0.0001      0.98     1.0       0.96   \n",
       "466           l1      600      1     0.1      0.98     1.0       0.96   \n",
       "469           l1      600      1  0.0001      0.98     1.0       0.96   \n",
       "667           l2      150      1    0.01      0.98     1.0       0.96   \n",
       "\n",
       "      Accuracy    AUC  \n",
       "1676     1.000  1.000  \n",
       "1516     1.000  1.000  \n",
       "1156     1.000  1.000  \n",
       "1196     1.000  1.000  \n",
       "1236     1.000  1.000  \n",
       "...        ...    ...  \n",
       "449      0.985  1.000  \n",
       "464      0.985  1.000  \n",
       "466      0.985  0.999  \n",
       "469      0.985  1.000  \n",
       "667      0.985  1.000  \n",
       "\n",
       "[224 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "penalty = ['l1', 'l2','elasticnet','None']\n",
    "Max_iter = []\n",
    "for k in range (1,15):\n",
    "    Max_iter.append(50*k)\n",
    "Eta =[]\n",
    "for k in range (-5,3):\n",
    "    Eta.append(10**(-k)) \n",
    "Alpha = []\n",
    "for k in range (0,5):\n",
    "    Alpha.append(10**(-k))\n",
    "\n",
    "#data = np.array([['penalty','Max_iter','Eta','Alpha','F1 score','recall','precision','accuracy','AUC',]])\n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True) # équilibrage dataset\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    test =False\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_train=np.ravel(y_train)\n",
    "    y_test=np.ravel(y_test)\n",
    "\n",
    "    #Méthode Perceptron simple\n",
    "\n",
    "    test =False\n",
    "    \n",
    "    for k in penalty :\n",
    "        for i in Max_iter :\n",
    "            for j in Eta :\n",
    "                for p in Alpha : \n",
    "                    \n",
    "                    #algo Perceptron\n",
    "                    model_Percep = Perceptron(penalty=k, max_iter=i, eta0=j, alpha=p)\n",
    "                    model_Percep.fit(X_train,y_train)\n",
    "                    y_pred_percep = model_Percep.predict(X_test)\n",
    "                    \n",
    "                    #fin algo Perceptron\n",
    "                \n",
    "                    \n",
    "                    #ROC curve\n",
    "                    clf_isotonic = CalibratedClassifierCV(model_Percep, cv='prefit', method='isotonic')\n",
    "                    #CV correspond à la validation croisée, si dataset déjà rééquilibré : cv = 'predict'\n",
    "                    clf_isotonic.fit(X_test, y_test)\n",
    "                    y_scores_Percep = clf_isotonic.predict_proba(X_test)\n",
    "    \n",
    "                    y_scores_Percep = y_scores_Percep[:, 1]\n",
    "                    \n",
    "                    F1_Percep = round(f1_score(y_test,y_pred_percep),3)\n",
    "                    recall_Percep = round(recall_score(y_test,y_pred_percep),3)\n",
    "                    precision_Percep = round(precision_score(y_test,y_pred_percep,zero_division=0),3)\n",
    "                    accuracy_Percep = round(accuracy_score(y_test,y_pred_percep),3)\n",
    "                    AUC_Percep = round(roc_auc_score(y_test, y_scores_Percep),3)\n",
    "                    data = np.append(data, [[k,i,j,p,F1_Percep,recall_Percep,precision_Percep,accuracy_Percep,AUC_Percep]],axis=0)\n",
    "                    \n",
    "                    if test == False :\n",
    "                        matrice_Percep = np.array([[k,i,j,p,F1_Percep,recall_Percep,precision_Percep,accuracy_Percep,AUC_Percep]])\n",
    "                        test = True\n",
    "                    else :\n",
    "                        matrice_Percep = np.append(matrice_Percep,np.array([k,i,j,p,F1_Percep,recall_Percep,precision_Percep,accuracy_Percep,AUC_Percep]).reshape(1,9),axis=0)\n",
    "        \n",
    "            #Fin méthode Percep\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(matrice_Percep, columns=['penalty','Max_iter','Eta','Alpha','F1 score','Recall','Precision','Accuracy','AUC'])\n",
    "#df=df.drop(df.index[0])\n",
    "df = df.astype({'F1 score': float, 'Recall': float,'Precision': float,'Accuracy': float,'AUC': float})\n",
    "filtered_values_1 = np.where((df['F1 score']>=0.96) & (df['Recall']>=0.925) & (df['Precision']>=0.925) & (df['AUC']>=0.925))\n",
    "display(df.iloc[filtered_values_1].sort_values(by=['F1 score'], ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_Perceptron = df.to_csv('data_csv_Perceptron.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achan\\AppData\\Local\\Temp/ipykernel_22992/112100171.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  classdata.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     1119.500000\n",
       "Max_iter        375.000000\n",
       "Eta           13888.888750\n",
       "Alpha             0.222220\n",
       "F1 score          0.652156\n",
       "Recall            0.688531\n",
       "Precision         0.633669\n",
       "Accuracy          0.852594\n",
       "AUC               0.855475\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classdata=pd.read_csv('data_csv_Perceptron.csv')\n",
    "classdata.mean()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
