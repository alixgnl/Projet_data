{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Méthode du perceptron mutlicouche (multilayer perceptron) qui est un type de réseau neuronal artificiel où l'information ne circule que dans un seul sens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, recall_score, accuracy_score, recall_score, f1_score, precision_score, roc_auc_score \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import scipy.io as sp\n",
    "import pandas as pd\n",
    "#from sklearn.decomposition import PCA\n",
    "import xlsxwriter\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "#Traitement du fichier .mat\n",
    "cancercell = sp.loadmat('breastw.mat')\n",
    "X = cancercell['X']\n",
    "y = cancercell['y']\n",
    "#print(cancercell)\n",
    "y=np.reshape(y,(683,))\n",
    "#Séparation des données d'apprentissage et des données tests\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y)\n",
    "#fin traitement mat\n",
    "\n",
    "#Algorithme Réseau de neurones = Perceptron multicouches\n",
    "\n",
    "# Solver : Algorithme choisit pour entraîner le réseaux. \n",
    "#       Lbfgs = optimiseur de la famille des méthodes quasi Nexton\n",
    "#       sgd = descente de gradient stochastique\n",
    "#       adam = optimiseur basé sur le gradient stochastique proposé par Kingma, Diederik et Jimmy Ba\n",
    "# hidden_layer_sizes : nombre de couches cachées et le nombre de neurones par couche cachée\n",
    "# Alpha : pas,vitesse avec laquelle l'algo va apprendre, Plus il sera petit, plus le réseau va prendre du temps pour converger vers la solution.\n",
    "# Random_state : état aléatoire d'initialisation du réseau.\n",
    "\n",
    "#Modèle1\n",
    "mlp1 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(8, 2), random_state=1)\n",
    "mlp1.fit(X_train, y_train)\n",
    "prediction1 = mlp1.predict(X_test)\n",
    "\n",
    "#Modèle2\n",
    "mlp2 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(9, 2), random_state=1) #modif du nombre de couches cachées par ex ici 9\n",
    "mlp2.fit(X_train, y_train)\n",
    "prediction2 = mlp2.predict(X_test)\n",
    "\n",
    "#Accuracy\n",
    "result1 = accuracy_score(y_test,prediction1)\n",
    "print(\"Accuracy 1 :\",result1)\n",
    "\n",
    "result2 = accuracy_score(y_test,prediction2)\n",
    "print(\"Accuracy 2 :\",result2)\n",
    "\n",
    "#ROC curve\n",
    "#Modèle 1 et 2 \n",
    "y_scores1 = mlp1.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores1[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"AUC 1 : \", roc_auc)\n",
    "\n",
    "y_scores2 = mlp2.predict_proba(X_test)\n",
    "fpr2, tpr2, threshold2 = roc_curve(y_test, y_scores2[:, 1])\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "print(\"AUC 2 : \", roc_auc2)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC 1 = %0.2f' % roc_auc)\n",
    "plt.plot(fpr2, tpr2, 'g', label = 'AUC 2 = %0.2f' % roc_auc2)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve Multilayer Perceptron')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "def create(row, col):\n",
    "    return [[[]for _ in range(col)]  for _ in range(row)]\n",
    "\n",
    "\n",
    "HLS=[]\n",
    "for j in range(2,10):\n",
    "    for k in range(2,10):\n",
    "        HLS.append((j,k))\n",
    "Alpha = [10**(-k) for k in range(4,8)] #\n",
    "Solver = ['lbfgs', 'sgd','adam']\n",
    "MC = create(3*len(HLS)*len(Alpha)+1,6)\n",
    "MC[0][0]='k (nb voisins)'\n",
    "MC[0][1]='w (poids)'\n",
    "MC[0][2]='a (algorithme))'\n",
    "MC[0][3]='AUC'\n",
    "MC[0][4]='Accuracy'\n",
    "MC[0][5]='Recall'\n",
    "i=1\n",
    "\n",
    "for k in HLS:\n",
    "    for a in Alpha:\n",
    "        for s in Solver:\n",
    "            MC[i][0]= str(k)\n",
    "            MC[i][1]= a\n",
    "            MC[i][2]= s\n",
    "\n",
    "            #algo prédiction\n",
    "            model = MLPClassifier(solver= s, alpha= a, hidden_layer_sizes= k, random_state=1)\n",
    "            model.fit(X_train,y_train)\n",
    "            prediction= model.predict(X_test)\n",
    "            y_scores = model.predict_proba(X_test)\n",
    "\n",
    "            \n",
    "            #  ROC curve\n",
    "            fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            MC[i][3]=(round(roc_auc, 3))\n",
    "\n",
    "            #Accuracy\n",
    "            acc = accuracy_score(y_test,prediction)\n",
    "            MC[i][4] = (round(acc,3))\n",
    "            \n",
    "            #Recall\n",
    "            recc = recall_score(y_test,prediction)\n",
    "            MC[i][5] = (round(recc,3))\n",
    "            \n",
    "            i += 1 \n",
    "\n",
    "print(MC)\n",
    "workbook = xlsxwriter.Workbook('Comparaison matrice Perceptron Multicouches.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "col = 0\n",
    "for row, data in enumerate(MC):\n",
    "    worksheet.write_row(row, col, data)\n",
    "workbook.close()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ines/Code_Projet_Data/Repository_Alix/Projet_data/dataset et tests/PerceptronMulticouches.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ines/Code_Projet_Data/Repository_Alix/Projet_data/dataset%20et%20tests/PerceptronMulticouches.ipynb#ch0000003?line=37'>38</a>\u001b[0m \u001b[39m#fin algo MLP\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ines/Code_Projet_Data/Repository_Alix/Projet_data/dataset%20et%20tests/PerceptronMulticouches.ipynb#ch0000003?line=39'>40</a>\u001b[0m y_pred_MLP \u001b[39m=\u001b[39m model_MLP\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ines/Code_Projet_Data/Repository_Alix/Projet_data/dataset%20et%20tests/PerceptronMulticouches.ipynb#ch0000003?line=40'>41</a>\u001b[0m y_pred_MLP \u001b[39m=\u001b[39m y_pred_MLP[:, \u001b[39m1\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ines/Code_Projet_Data/Repository_Alix/Projet_data/dataset%20et%20tests/PerceptronMulticouches.ipynb#ch0000003?line=43'>44</a>\u001b[0m F1_MLP \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(f1_score(y_test,y_pred_MLP),\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ines/Code_Projet_Data/Repository_Alix/Projet_data/dataset%20et%20tests/PerceptronMulticouches.ipynb#ch0000003?line=44'>45</a>\u001b[0m recall_MLP \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(recall_score(y_test,y_pred_MLP),\u001b[39m3\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "HLS=[]\n",
    "for j in range(2,15):\n",
    "    for k in range(2,15):\n",
    "        HLS.append((j,k))\n",
    "Alpha = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "Solver = ['lbfgs', 'sgd','adam']\n",
    "Activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "Max_iter = []\n",
    "for k in range(1,10):\n",
    "    Max_iter.append(2*k)\n",
    "    \n",
    "data = np.array([['Hidden_layers','Alpha','solver','Activation','Max_iter','F1 score','recall','precision','accuracy','AUC',]])    \n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True) # équilibrage dataset\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    test =False\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_train=np.ravel(y_train)\n",
    "    y_test=np.ravel(y_test)\n",
    "\n",
    "    #Méthode MLP\n",
    "\n",
    "    test =False\n",
    "    \n",
    "    for k in HLS :\n",
    "        for i in Alpha :\n",
    "            for j in Solver :\n",
    "                for p in Activation : \n",
    "                    for n in Max_iter :\n",
    "                        \n",
    "                        #algo MLP\n",
    "                        model_MLP = MLPClassifier(hidden_layer_sizes = k, alpha = i, solver = j, activation = p, max_iter = n)\n",
    "                        model_MLP.fit(X_train,y_train)\n",
    "                        y_pred_MLP = model_MLP.predict(X_test)\n",
    "                        \n",
    "                        #fin algo MLP\n",
    "                    \n",
    "                        y_pred_MLP = model_MLP.predict(X_test)\n",
    "                        \n",
    "                    \n",
    "                        \n",
    "                        F1_MLP = round(f1_score(y_test,y_pred_MLP),3)\n",
    "                        recall_MLP = round(recall_score(y_test,y_pred_MLP),3)\n",
    "                        precision_MLP = round(precision_score(y_test,y_pred_MLP,zero_division=0),3)\n",
    "                        accuracy_MLP = round(accuracy_score(y_test,y_pred_MLP),3)\n",
    "                        AUC_MLP = round(roc_auc_score(y_test, y_pred_MLP),3)\n",
    "\n",
    "                        data = np.append(data, [[k,i,j,p,n,F1_MLP,recall_MLP,precision_MLP,accuracy_MLP,AUC_MLP]],axis=0)\n",
    "                        \n",
    "                        #Fin méthode MLP\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Hidden_layers','Alpha','solver','Activation','Max_iter','F1 score','recall','precision','accuracy','AUC'])\n",
    "df=df.drop(df.index[0])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
