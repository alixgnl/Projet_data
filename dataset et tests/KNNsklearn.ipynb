{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import scipy.io as sp\n",
    "import logging\n",
    "\n",
    "#traitement mat\n",
    "cancercell=sp.loadmat('breastw.mat')\n",
    "X = cancercell['X']\n",
    "y = cancercell['y']\n",
    "#print(cancercell)\n",
    "y=np.reshape(y,(683,))\n",
    "#Séparation des données d'apprentissage et des données tests\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y)\n",
    "#fin traitement mat\n",
    "\n",
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN')\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "i=0\n",
    "MC=np.zeros((48,2))\n",
    "for k in [3, 4, 5, 6, 7, 8]:\n",
    "    for w in ['uniform','distance']:\n",
    "        for a in ['auto','ball_tree','kd_tree','brute']:\n",
    "\n",
    "            MC[i,0]=[k,w,a]\n",
    "            #algo knn\n",
    "            model = KNeighborsClassifier(n_neighbors=k, weights=w, algorithm=a)\n",
    "            model.fit(X_train,y_train)\n",
    "            prediction= model.predict(X_test)\n",
    "            model_PCA = PCA(n_components=2)\n",
    "            data_reduced = model_PCA.fit_transform(X_test)\n",
    "            #fin algo knn\n",
    "\n",
    "            logging.debug('i=%d : k=%d, w=%s, a=%s' % (i, k, w, a))\n",
    "\n",
    "            #print(model.predict_proba(X_test))\n",
    "            y_scores = model.predict_proba(X_test)\n",
    "\n",
    "            #graphique\n",
    "            #  ROC curve\n",
    "            fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            MC[i,1] = roc_auc\n",
    "\n",
    "            logging.debug('i=%d : AUC=%f' % (i, roc_auc))\n",
    "            #plt.plot(fpr, tpr, 'b', label = 'AUC = %0.4f' % roc_auc)\n",
    "            #plt.plot(fpr, tpr, 'b', label = 'AUC {}'.format(k) & '%0.4f' % roc_auc)\n",
    "            #fin graphique\n",
    "            i += 1 \n",
    "    \n",
    "print(MC)    \n",
    "\n",
    "\"\"\"\"\"\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(data_reduced[:,0],data_reduced[:,1],c=prediction)\n",
    "plt.title(\"Résultat pred\")\n",
    "maline = mpatches.Patch(color='yellow', label='maline')\n",
    "benine = mpatches.Patch(color='purple', label='benine')\n",
    "plt.legend(handles=[maline,benine])\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(data_reduced[:,0],data_reduced[:,1],c=y_test)\n",
    "plt.title(\"Résultat vrai\")\n",
    "maline = mpatches.Patch(color='yellow', label='maline')\n",
    "benine = mpatches.Patch(color='purple', label='benine')\n",
    "plt.legend(handles=[maline,benine])\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[216   6]\n",
      " [  5 115]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       222\n",
      "           1       0.95      0.96      0.95       120\n",
      "\n",
      "    accuracy                           0.97       342\n",
      "   macro avg       0.96      0.97      0.96       342\n",
      "weighted avg       0.97      0.97      0.97       342\n",
      "\n",
      "Accuracy : 0.9678362573099415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "result = confusion_matrix(y_test, prediction)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(result)\n",
    "result1 = classification_report(y_test, prediction)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)\n",
    "result2 = accuracy_score(y_test,prediction)\n",
    "print(\"Accuracy :\",result2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d66c663352a93aca0402de51e85d6aa16823dfcb804efd49b2a93bf67c0dc337"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
